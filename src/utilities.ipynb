{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
      ],
      "metadata": {
        "id": "hkv7_NuBXV7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_ids are the numeric representations of the tokens.\n",
        "#Attention_mask is useful when we add padding to the input tokens. The attention mask tells which input_ids correspond to padding. \n",
        "#Padding is added because all the input sentences to be of the same length (at least for a batch) so that we are able to form tensor objects properly. \n",
        "#Use tokenizer.encode_plus function for obtaining input_ids, attention_mask\n",
        "\n",
        "def encode(data, tokenizer, maxlength):\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    for text in data:\n",
        "        tokenized_text = tokenizer.encode_plus(text,\n",
        "                                               truncation=True,\n",
        "                                               max_length=maxlength,\n",
        "                                               add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                               pad_to_max_length=True,\n",
        "                                               return_attention_mask=True)\n",
        "        input_ids.append(tokenized_text['input_ids'])\n",
        "        attention_mask.append(tokenized_text['attention_mask'])\n",
        "    \n",
        "    return torch.tensor(input_ids, dtype=torch.long), torch.tensor(attention_mask, dtype=torch.long)"
      ],
      "metadata": {
        "id": "B7HsJ9D7R662"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(df, tokenizer, maxlength, batchsize):\n",
        "  x = list(df['Tweet'].values)\n",
        "  y_indices = df['Stance'].apply(lambda each_y: dataset['labels'].index(each_y))\n",
        "  y = torch.tensor(list(y_indices), dtype=torch.long)\n",
        "  input_ids, attention_mask = encode(x, tokenizer,maxlength)\n",
        "  tensor_dataset = TensorDataset(input_ids, attention_mask, y)\n",
        "  tensor_randomsampler = RandomSampler(tensor_dataset)\n",
        "  tensor_dataloader = DataLoader(tensor_dataset, sampler=tensor_randomsampler, batch_size=batchsize)\n",
        "  return tensor_dataloader"
      ],
      "metadata": {
        "id": "a8drL9cITOL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "HJdktLkETQQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "Flh5K1nqTUxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "fdoA0adFTWjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_summary(description, true_labels, predictions, target_classes):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  print(classification_report(true_labels, predictions,  digits=3, zero_division=0, target_names=target_classes))"
      ],
      "metadata": {
        "id": "2aC4woMcTYaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(model,optimizer, learning_rate,epsilon,weight_decay ):\n",
        "  if optimizer == \"adam\":\n",
        "    optimizer = transformers.AdamW(\n",
        "        model.parameters(),\n",
        "        lr = learning_rate, \n",
        "        correct_bias=False,\n",
        "        weight_decay=weight_decay,\n",
        "        eps = epsilon)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "N9RbCKOHTZ3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_scheduler(model,optimizer,epochs,train_batch_len):\n",
        "    tr_steps = train_batch_len * epochs\n",
        "    num_warmup_steps = int(0.1*tr_steps)\n",
        "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer, \n",
        "        num_training_steps = tr_steps,\n",
        "        num_warmup_steps = num_warmup_steps\n",
        "    )\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "7Vq10fsPTbQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_name,label_count):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=label_count, \n",
        "        output_hidden_states=True, \n",
        "        output_attentions=True)\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "QQvK_ethTcX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(batch, val_batch,model, optimizer, scheduler, epochs, device,max_grad_norm):\n",
        "    train_loss_arr = []\n",
        "    val_loss = []\n",
        "    val_accuracy = []\n",
        "    training_stats = []\n",
        "\n",
        "     # Early stopping\n",
        "    patience = 5\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        t0 = time.time()\n",
        "        print(\"\\nepoch : \", e+1)\n",
        "        print(\"batch size : \",len(batch))\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Set the mode to training\n",
        "        for i, batch_tuple in enumerate(batch):\n",
        "            batch_tuple = (t.to(device) for t in batch_tuple)\n",
        "            input_ids, attention_mask, labels = batch_tuple\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss, logits, hidden_states_output, attention_mask_output = outputs\n",
        "            running_loss += outputs.loss.item() \n",
        "            if i % 500 == 0:\n",
        "                print(\"Training loss - {0}, iteration - {1}/{2}\".format(outputs.loss, e + 1, i))\n",
        "            model.zero_grad()\n",
        "            optimizer.zero_grad()\n",
        "            outputs.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),max_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "        avg_train_loss = running_loss/len(batch)\n",
        "        train_loss_arr.append(avg_train_loss)\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        model.eval()\n",
        "        total_eval_loss = 0\n",
        "        total_eval_accuracy = 0\n",
        "        # Evaluate data for one epoch\n",
        "        for i, batch_cpu in enumerate(val_batch):\n",
        "            batch_gpu = (t.to(device) for t in batch_cpu)\n",
        "            input_ids_gpu, attention_mask, labels = batch_gpu\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids=input_ids_gpu, attention_mask=attention_mask, labels=labels)\n",
        "            total_eval_loss += outputs.loss.item()\n",
        "            if i % 100 == 0:\n",
        "                print(\"Validation loss - {0}, iteration - {1}/{2}\".format(outputs.loss, e + 1, i))\n",
        "            logits =  outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            #wandb.log({\"Validation Running Loss\": outputs.loss.item()})\n",
        "        avg_val_accuracy = total_eval_accuracy / len(val_batch)\n",
        "        val_accuracy.append(avg_val_accuracy)\n",
        "        avg_val_loss = total_eval_loss/len(val_batch)\n",
        "        val_loss.append(avg_val_loss)\n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        # early_stopping needs the validation loss to check if it has decresed, and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(avg_val_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "        training_stats.append(\n",
        "              {\n",
        "                'epoch': e + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "              }\n",
        "       )\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return train_loss_arr,val_loss,val_accuracy,training_stats,model"
      ],
      "metadata": {
        "id": "orS7aUIkTkly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(batch, model, device):\n",
        "    input_ids, predictions, true_labels, attentions = [], [], [], []\n",
        "    model.eval()\n",
        "    for i, batch_cpu in enumerate(batch):\n",
        "        running_loss = 0.0\n",
        "        batch_gpu = (t.to(device) for t in batch_cpu)\n",
        "        input_ids_gpu, attention_mask, labels = batch_gpu\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids_gpu, attention_mask=attention_mask, labels=labels)\n",
        "            logits =  outputs.logits.cpu()\n",
        "            prediction = torch.argmax(logits, dim=1).tolist()\n",
        "            true_label = labels.cpu().tolist()\n",
        "            input_ids_cpu = input_ids_gpu.cpu().tolist()\n",
        "            attention_last_layer = outputs.attentions[-1].cpu() # selection the last attention layer\n",
        "            attention_softmax = attention_last_layer[:,-1, 0].tolist()  # selection the last head attention of CLS token\n",
        "            input_ids += input_ids_cpu\n",
        "            predictions += prediction\n",
        "            true_labels += true_label\n",
        "            attentions += attention_softmax\n",
        "    return input_ids, predictions, true_labels, attentions"
      ],
      "metadata": {
        "id": "XcaRjcBOTk65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stopword_es = nltk.corpus.stopwords.words('spanish')\n",
        "stopword_it = nltk.corpus.stopwords.words('italian')\n",
        "stopword_fr = nltk.corpus.stopwords.words('french')\n",
        "stopword_en = nltk.corpus.stopwords.words('english')\n",
        "stopword_ca = nltk.corpus.stopwords.words('catalan')\n",
        "\n",
        "#set up punctuations we want to be replaced\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
        "\n",
        "def clean(text,lang):\n",
        "    #remove puctuation\n",
        "    text = REPLACE_NO_SPACE.sub(\"\", text.lower()) # convert all tweets to lower cases\n",
        "    text = REPLACE_WITH_SPACE.sub(\" \", text)\n",
        "\n",
        "    if lang=='EN':\n",
        "      stopword_lst = stopword_en\n",
        "    elif lang=='IT':\n",
        "      stopword_lst = stopword_it\n",
        "    elif lang=='FR':\n",
        "      stopword_lst = stopword_fr\n",
        "    elif lang=='CA':\n",
        "      stopword_lst = stopword_ca\n",
        "    elif lang=='SP':\n",
        "      stopword_lst = stopword_es\n",
        "\n",
        "    \" \".join([word for word in str(text).split() if word not in stopword_lst])\n",
        "    return text\n",
        "\n",
        "def clean_mul(row):\n",
        "    #remove puctuation\n",
        "    text = row['Tweet']\n",
        "    lang = row['Language']\n",
        "    text = REPLACE_NO_SPACE.sub(\"\", text.lower()) # convert all tweets to lower cases\n",
        "    text = REPLACE_WITH_SPACE.sub(\" \", text)\n",
        "\n",
        "    if lang=='EN':\n",
        "      stopword_lst = stopword_en\n",
        "    elif lang=='IT':\n",
        "      stopword_lst = stopword_it\n",
        "    elif lang=='FR':\n",
        "      stopword_lst = stopword_fr\n",
        "    elif lang=='CA':\n",
        "      stopword_lst = stopword_ca\n",
        "    elif lang=='SP':\n",
        "      stopword_lst = stopword_es\n",
        "\n",
        "    \" \".join([word for word in str(text).split() if word not in stopword_lst])\n",
        "    return text "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9A4qbtwTmV9",
        "outputId": "4494777e-58ed-4c86-97e6-022f64f8de63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MUSE(train,val,test):\n",
        "    X_train = []\n",
        "    for r in tqdm(train.Tweet.values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_train.append(review_emb)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = train.Stance.values\n",
        "\n",
        "\n",
        "    X_val = []\n",
        "    for r in tqdm(val.Tweet.values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_val.append(review_emb)\n",
        "\n",
        "    X_val = np.array(X_val)\n",
        "    y_val = val.Stance.values\n",
        "\n",
        "    X_test = []\n",
        "    for r in tqdm(test.Tweet.values):\n",
        "        emb = use(r)\n",
        "        review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "        X_test.append(review_emb)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = test.Stance.values\n",
        "    return X_train,y_train,X_val,y_val,X_test,y_test"
      ],
      "metadata": {
        "id": "o3jLPDOOT1e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]"
      ],
      "metadata": {
        "id": "4d-Lt8FdT4zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1score(truelabel, prediction):\n",
        "  print(\"Micro Average Precision : \",precision_score(truelabel, prediction, average='micro')) \n",
        "  print(\"Micro Average Recall : \",recall_score(truelabel, prediction, average='micro'))  \n",
        "  print(\"Micro Average F1-Score : \",f1_score(truelabel, prediction, average='micro')) \n",
        "  print(\"............................\")\n",
        "  print(\"Macro Average Precision : \",precision_score(truelabel, prediction, average='macro')) \n",
        "  print(\"Macro Average Recall : \",recall_score(truelabel, prediction, average='macro'))  \n",
        "  print(\"Macro Average F1-Score : \",f1_score(truelabel, prediction, average='macro')) "
      ],
      "metadata": {
        "id": "mln7CuiNWGVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotEarlyStopCheckpoint(train_loss_arr,val_loss,imgName):\n",
        "  # visualize the loss as the network trained\n",
        "  fig = plt.figure(figsize=(8,5))\n",
        "  plt.plot(range(1,len(train_loss_arr)+1),train_loss_arr, label='Training Loss')\n",
        "  plt.plot(range(1,len(val_loss)+1),val_loss,label='Validation Loss')\n",
        "\n",
        "  # find position of lowest validation loss\n",
        "  minposs = val_loss.index(min(val_loss))+1 \n",
        "  plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('loss')\n",
        "  plt.ylim(0, 1.5) # consistent scale\n",
        "  plt.xlim(0, len(train_loss_arr)+1) # consistent scale\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  fig.savefig(imgName, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "LUbZmDcTX_VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lossCurve(train_loss_arr,val_loss,imgName):\n",
        "  epoch_range = range(1, len(train_loss_arr) + 1)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(epoch_range,train_loss_arr, '-o', label=\"train\")\n",
        "  plt.plot(epoch_range,val_loss, '-o', label=\"validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss change over epoch\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  fig.savefig(imgName, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "vzKblnYUj7We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracyCurve(train_loss_arr,val_accuracy,imgName):\n",
        "  epoch_range = range(1, len(train_loss_arr) + 1)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(epoch_range,val_accuracy, '-o', label=\"validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.title(\"Accuracy over epoch\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  fig.savefig(imgName, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "wmhyQY58kRnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(training_stats):\n",
        "  # Display floats with two decimal places.\n",
        "  pd.set_option('precision', 2)\n",
        "\n",
        "  # Create a DataFrame from our training statistics.\n",
        "  df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "  # Use the 'epoch' as the row index.\n",
        "  df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "  # A hack to force the column headers to wrap.\n",
        "  #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "  # Display the table.\n",
        "  print(df_stats)"
      ],
      "metadata": {
        "id": "kQbM7V-6kfpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(true_labels, predictions,label):\n",
        "  fpr, tpr, _ = roc_curve(true_labels, predictions, pos_label=label)\n",
        "  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ],
      "metadata": {
        "id": "Fe2Ur70ok_vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gridsearch(prediction_pipeline,parameter,train,Y_train):\n",
        "    #Tuning paramters to improve model performance\n",
        "    grid_search = GridSearchCV(prediction_pipeline, param_grid=parameter, n_jobs=1, verbose=1, scoring='f1_weighted', cv=5)\n",
        "\n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"pipeline:\", [name for name, _ in prediction_pipeline.steps])\n",
        "    print(\"parameters:\")\n",
        "    pprint(parameter)\n",
        "    t0 = time()\n",
        "    grid_search.fit(train, Y_train)\n",
        "    print(\"done in %0.3fs\" % (time() - t0))\n",
        "    print()\n",
        "\n",
        "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\n",
        "    for param_name in sorted(parameter.keys()):\n",
        "      print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "metadata": {
        "id": "KcYhPpV9pxH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}